{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc993d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa8844",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ad0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = os.getcwd() + \"/data/text/pac/\"\n",
    "pac_dir = os.getcwd() + \"/../pacnews/\"\n",
    "\n",
    "for file in os.listdir(pac_dir):\n",
    "    file = pac_dir + file\n",
    "    if \"Factiva\" in file and \".txt\" in file:\n",
    "        new_file_name = (file.replace(\"Factiva-\", \"\")\n",
    "                             .replace(\"2023\", \"\")\n",
    "                             .replace(r\"(\", \"\")\n",
    "                             .replace(r\")\", \"\")\n",
    "                             .replace(\" \", \"\"))    \n",
    "        os.rename(file, new_file_name)\n",
    "        \n",
    "filepaths = [pac_dir + file for file in os.listdir(pac_dir) if \".txt\" in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d617c",
   "metadata": {},
   "source": [
    "Converting RTF file to TXT by following commands on Mac:\n",
    "`textutil -convert txt *.rtf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7c9a95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "news_info = {\"title\": [], \"date\": [], \"news\": []}\n",
    "for fp in filepaths: \n",
    "    with open(fp, 'r') as file:\n",
    "        text = file.read()\n",
    "        entries = text.split(\"\\x0c\")\n",
    "        for idx, entry in enumerate(entries):\n",
    "            entry_lst = entry.strip().split(\"\\n\\n\")\n",
    "            title = entry_lst[0]\n",
    "            date = entry_lst[1].split(\"\\n\")[1]\n",
    "            if \"words\" in date:\n",
    "                date = entry_lst[1].split(\"\\n\")[2]\n",
    "            entry_length = len(entry_lst)\n",
    "            if idx == len(entries) - 1:\n",
    "                content = \"\".join((entry_lst[i]) for i in range(entry_length)\n",
    "                                  if i > 1 and i < entry_length - 5)\n",
    "            else:\n",
    "                content = \"\".join((entry_lst[i]) for i in range(entry_length)\n",
    "                                  if i > 1 and i < entry_length - 2)\n",
    "            news_info[\"title\"].append(title)\n",
    "            news_info[\"date\"].append(date)\n",
    "            news_info[\"news\"].append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94aeee4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame(news_info)\n",
    "news_df[\"date\"] = pd.to_datetime(news_df[\"date\"])\n",
    "news_df = (news_df.drop_duplicates()\n",
    "                  .sort_values(by=\"date\", ascending=True)\n",
    "                  .reset_index(drop=True))\n",
    "news_df[\"news\"] = news_df[\"news\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ffe3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_idx = news_df[[\"title\"]].drop_duplicates().index\n",
    "news_df = news_df.iloc[unique_idx].reset_index(drop=True)\n",
    "news_df[\"location\"] = news_df[\"news\"].apply(\n",
    "    lambda x: \"\".join(i for i in x.split(\"--\")[0].split(\",\")[:-1]))\n",
    "news_df.to_csv(target_dir+\"/pac_news_before_2021.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7ecca",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e94c3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 420/420 [24:55<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "url_info = {\"url\": [], \"title\": [], \"date\": [], \"category\": []}\n",
    "page_range = range(1, 421)\n",
    "\n",
    "with tqdm(total=len(page_range)) as pbar:\n",
    "    for i in page_range:\n",
    "        content = load_page(\"https://pina.com.fj/category/news/page/\" + str(i),\n",
    "                            5)\n",
    "        soup = BeautifulSoup(content)\n",
    "        for item in soup.find_all(\n",
    "                class_=\"td_module_10 td_module_wrap td-animation-stack\"):\n",
    "            title = item.find(\"h3\").text\n",
    "            url = item.find(\"h3\").find(\"a\")[\"href\"]\n",
    "            date = item.find(class_=\"td-post-date\")\n",
    "            category = item.find(class_=\"td-post-category\")\n",
    "            url_info[\"url\"].append(url)\n",
    "            url_info[\"title\"].append(title)\n",
    "            url_info[\"date\"].append(date.text)\n",
    "            url_info[\"category\"].append(category.text)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf6438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac_urls = pd.DataFrame(url_info).drop_duplicates().reset_index(drop=True)\n",
    "pac_urls[\"date\"] = pd.to_datetime(pac_urls[\"date\"])\n",
    "\n",
    "target_dir = os.getcwd() + \"/data/text/pac/\"\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "    pac_urls.to_csv(target_dir + \"pac_news_urls.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a2aa7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_news_pac(url: str):\n",
    "    content = load_page(url, 5)\n",
    "    soup = BeautifulSoup(content)\n",
    "    news = soup.find(class_=\"td-post-content tagdiv-type\").text\n",
    "    tags_lst = soup.find(class_=\"td-post-source-tags\").find_all(\"li\")\n",
    "    tags = \"\".join(i.text.lower() + \" \" for i in tags_lst if i.text.lower() != \"tags\")\n",
    "    return [url, news, tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be7c08f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 4200/4200 [50:40<00:00,  1.38pages/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "\n",
    "max_workers = multiprocessing.cpu_count() + 4\n",
    "output = []\n",
    "urls = pac_urls.url.tolist()\n",
    "\n",
    "with tqdm(total=len(urls), unit=\"pages\") as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_url = {\n",
    "            executor.submit(extract_news_pac, url): url\n",
    "            for url in urls\n",
    "        }\n",
    "        for future in as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (url, exc))\n",
    "            else:\n",
    "                output.append(data)\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f40f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac_news = pd.DataFrame(output, columns=[\"url\", \"news\", \"tag\"])\n",
    "pac_news[\"news\"] = pac_news[\"news\"].str.replace(\"\\n\", \"\")\n",
    "pac_news.to_csv(target_dir+\"pac_news_2020-23.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "po",
   "language": "python",
   "name": "po"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
