{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af97e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81ee3ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def process_data(filename, folderpath):\n",
    "    df = pd.read_csv(folderpath + filename).drop(\"Unnamed: 0\", axis=1)\n",
    "    df[\"news\"] = df[\"news\"].replace(\"\\n\", \"\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df[\"ym\"] = [str(d.year) + \"-\" + str(d.month) for d in df.date]\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_entities(corpus: str):\n",
    "    doc = nlp(corpus)\n",
    "    ner_labels = [\"LOC\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]\n",
    "    ner_dict = {\"ner\": \"\"}\n",
    "    for e in doc.ents:\n",
    "        if e.label_ in ner_labels and e.text not in ner_dict[\"ner\"]:\n",
    "            ner_dict[\"ner\"] += e.text + \", \"\n",
    "\n",
    "    ner_dict[\"ner\"] =  ner_dict[\"ner\"][:-2]\n",
    "    return ner_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8245956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 819/819 [00:50<00:00, 16.16it/s]\n",
      "/var/folders/kn/jw0y9v615mjgg3_51g3s73zh0000gn/T/ipykernel_27371/1890609972.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14071/14071 [13:19<00:00, 17.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46350/46350 [32:13<00:00, 23.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2597/2597 [02:19<00:00, 18.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6080/6080 [04:20<00:00, 23.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 140/140 [00:09<00:00, 14.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9062/9062 [05:10<00:00, 29.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1709/1709 [01:25<00:00, 20.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2053/2053 [01:12<00:00, 28.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11139/11139 [08:45<00:00, 21.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9217/9217 [07:28<00:00, 20.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14484/14484 [12:12<00:00, 19.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29469/29469 [28:11<00:00, 17.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 783/783 [00:49<00:00, 15.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 577/577 [00:32<00:00, 17.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6278/6278 [04:41<00:00, 22.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4640/4640 [04:17<00:00, 18.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2197/2197 [02:21<00:00, 15.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5661/5661 [03:53<00:00, 24.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4366/4366 [02:52<00:00, 25.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35489/35489 [41:52<00:00, 14.13it/s]\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.getcwd() + \"/data/text\"\n",
    "country_dirs = [\n",
    "    f\"{parent_dir}/{file}/\" for file in os.listdir(parent_dir)\n",
    "    if file != \".DS_Store\"\n",
    "]\n",
    "\n",
    "for country_dir in country_dirs[1:]:\n",
    "    files = [\n",
    "        file for file in os.listdir(country_dir)\n",
    "        if \"news\" in file and \"ner\" not in file\n",
    "    ]\n",
    "    for file in files:\n",
    "        df = process_data(file, country_dir)\n",
    "        name = file.replace(\".csv\", \"\") + \"_ner.csv\"\n",
    "    \n",
    "        output = []\n",
    "        with tqdm(total=len(df)) as pbar:\n",
    "            for news in df[\"news\"]:\n",
    "                if isinstance(news, str):\n",
    "                    ner_dict = extract_entities(news)\n",
    "                else:\n",
    "                    ner_dict = {\"ner\": \"Missing\"}\n",
    "                output.append(ner_dict)\n",
    "                pbar.update(1)\n",
    "\n",
    "        ner_df = pd.DataFrame(output)\n",
    "        ner_df[\"url\"] = df[\"url\"].tolist()\n",
    "        ner_df.to_csv(country_dir + name, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00542b1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9062/9062 [05:04<00:00, 29.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1709/1709 [01:23<00:00, 20.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2053/2053 [01:10<00:00, 29.02it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11139/11139 [08:24<00:00, 22.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9217/9217 [07:17<00:00, 21.08it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14484/14484 [11:54<00:00, 20.28it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files = [file for file in os.listdir(target_dir) if \"news\" in file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4ea9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for url, ner in zip(ner_df[\"url\"], ner_df[\"ner\"]):\n",
    "    if \"risk\" in ner.lower():\n",
    "        urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "850f3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_dir = os.getcwd() + \"/data/text/abc_au/\"\n",
    "abc_files = [file for file in os.listdir(abc_dir) if \"news\" in file]\n",
    "test = pd.read_csv(abc_dir + abc_files[3]).drop(\"Unnamed: 0\", axis=1)\n",
    "test[\"tags\"] = test[\"tags\"].fillna(\"missing\").str.lower()\n",
    "tag_dict = {}\n",
    "for tag in test.tags:\n",
    "    tag_list = tag.split(\",\")[:-1]\n",
    "    tag_list = [i.lower().strip() for i in tag_list]\n",
    "    for i in tag_list:\n",
    "        if i not in tag_dict.keys():\n",
    "            tag_dict.update({str(i): 1})\n",
    "        else:\n",
    "            tag_dict[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8eafbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_count(data: pd.DataFrame, column: str):\n",
    "    count_df = (data.set_index(\"date\").groupby(\"ym\")[[\n",
    "        str(column)\n",
    "    ]].count().reset_index().rename({str(column): str(column) + \"_count\"},\n",
    "                                    axis=1))\n",
    "    return count_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "po",
   "language": "python",
   "name": "po"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
