{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9520d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import tabula\n",
    "import PyPDF2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e885c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.getcwd() + \"/data/tourism/vanuatu/2013-TM-06-June_News.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c128ce",
   "metadata": {},
   "source": [
    "## Tonga \n",
    "### Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999ac755",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/Statistical-Bulletin-on-International-Arrivals-and-Departures-2021.pdf',\n",
       " '/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/Migration-Report-Dec-2017.pdf',\n",
       " '/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/Migration-December-Report-2019.pdf',\n",
       " '/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/12-December-Migration-Report-2014.pdf',\n",
       " '/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/12-December-Migration-Report-2015.pdf',\n",
       " '/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/Migration-December-Report-2020.pdf',\n",
       " '/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/12-December-Migration-Report-2013.pdf',\n",
       " '/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/12-Migration-Report-Dec-2016.pdf',\n",
       " '/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/12-December-Migration-2012.pdf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tonga_lsts = os.listdir(\"data/tourism/tonga\")\n",
    "filepaths = list()\n",
    "for path in tonga_lsts:\n",
    "    folder_path = os.getcwd() + \"/data/tourism/tonga/\"\n",
    "    if \"Dec\" in path:\n",
    "        filepaths.append(folder_path + path)\n",
    "    elif \"2021\" and \"Bulletin\" in path:\n",
    "        filepaths.append(folder_path + path)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77190c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def locate_table(filepath: str,\n",
    "                 search_string: str,\n",
    "                 ignore_case=False):\n",
    "\n",
    "    search_lst = list()\n",
    "    reader = PyPDF2.PdfReader(filepath)\n",
    "\n",
    "    for page_num, page in enumerate(reader.pages):\n",
    "        try:\n",
    "            page_text = page.extract_text()\n",
    "            hits = None\n",
    "            if ignore_case == False:\n",
    "                hits = re.search(search_string, page_text.lower())\n",
    "            else:\n",
    "                hits = re.search(\n",
    "                    search_string, page_text.lower(), re.IGNORECASE)\n",
    "\n",
    "            if hits:\n",
    "                search_lst.append(page_num+1)\n",
    "        except:\n",
    "            pass\n",
    "    return {\"table_loc\": search_lst}\n",
    "\n",
    "\n",
    "def load_pdf(filepath: str,\n",
    "             search_string: str,\n",
    "             table_page: int,\n",
    "             table_seq=0):\n",
    "\n",
    "    table_loc = locate_table(filepath, search_string,\n",
    "                             ignore_case=True)[\"table_loc\"]\n",
    "    if len(table_loc) != 0:\n",
    "        table_page = table_loc[-1]\n",
    "        dfs = tabula.read_pdf(filepath, pages=table_page, stream=True)\n",
    "        if len(dfs) > 1:\n",
    "            print(f\"The page has {len(dfs)} tables.\")\n",
    "            df = dfs[table_seq]\n",
    "\n",
    "        else:\n",
    "            df = dfs[0]\n",
    "            df.columns = df.iloc[0, :].to_list()\n",
    "    else:\n",
    "        dfs = tabula.read_pdf(filepath, pages=\"all\", stream=True)\n",
    "        df = dfs[table_page]\n",
    "        df.columns = df.iloc[0, :].to_list()\n",
    "\n",
    "    df = df.iloc[1:].reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_time(df: pd.DataFrame,\n",
    "               time_var: str):\n",
    "\n",
    "    year_idx, month_idx = list(), list()\n",
    "    for idx in df.index:\n",
    "        if (str(df[time_var][idx]).isdigit() == True):\n",
    "            year_idx.append(idx)\n",
    "        else:\n",
    "            month_idx.append(idx)\n",
    "\n",
    "    latest_year_idx = max(year_idx)\n",
    "\n",
    "    return latest_year_idx, year_idx, month_idx\n",
    "\n",
    "\n",
    "def detect_year(series: pd.Series):\n",
    "    nacheck = pd.isna(series)\n",
    "    start_year = int(series[nacheck == False][0])\n",
    "    return start_year\n",
    "\n",
    "\n",
    "def generate_time(df: pd.DataFrame,\n",
    "                  start_year: int):\n",
    "\n",
    "    years = [start_year + idx // 12 for idx in df.index]\n",
    "    df[\"Year\"] = years\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_separator(df: pd.DataFrame):\n",
    "\n",
    "    colnames = df.columns\n",
    "    for col in colnames:\n",
    "        try:\n",
    "            if df[col].dtype == \"O\":\n",
    "                df[col] = (df[col].str.replace(\",\", \"\")\n",
    "                                  .str.replace(\"-\", \"\")\n",
    "                                  .str.replace(\"(\", \"\")\n",
    "                                  .str.replace(\")\", \"\")\n",
    "                                  .str.replace(\" \", \"\"))\n",
    "        except:\n",
    "            print(col, \"might have an error.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def separate_data(df: pd.DataFrame,\n",
    "                  var: str,\n",
    "                  split_rule: str):\n",
    "\n",
    "    splited_lst = var.split(split_rule)\n",
    "    var_number = len(splited_lst)\n",
    "\n",
    "    obj = dict()\n",
    "    for i in range(var_number):\n",
    "        obj[str(splited_lst[i])] = []\n",
    "\n",
    "    for i in df[var]:\n",
    "        elems = i.split(\" \")\n",
    "        length = len(elems)\n",
    "        if length == var_number:\n",
    "            idx, var = 0, list(obj.keys())\n",
    "            while idx < length:\n",
    "                key, val = var[idx], elems[idx]\n",
    "                obj[key].append(val)\n",
    "                idx += 1\n",
    "\n",
    "        elif length < var_number:\n",
    "            idx, var = 0, list(obj.keys())\n",
    "            while idx < length and len(elems) != 0:\n",
    "                key, val = var[idx], elems[idx].split(\" \")[0]\n",
    "                obj[key].append(val)\n",
    "                elems = i.replace(val, \"\").strip()\n",
    "                idx += 1\n",
    "            else:\n",
    "                key, val = var[idx], 0\n",
    "                obj[key].append(val)\n",
    "                idx += 1\n",
    "\n",
    "        else:\n",
    "            idx, var = 0, list(obj.keys())\n",
    "            while idx < var_number:\n",
    "                key, val = var[idx], elems[idx]\n",
    "                obj[key].append(val)\n",
    "                idx += 1\n",
    "            else:\n",
    "                key, val = var[-1], elems[idx]\n",
    "                prev_val = obj[key][-1]\n",
    "                obj[key][-1] = prev_val + val\n",
    "\n",
    "    for i in range(var_number):\n",
    "        df[str(splited_lst[i])] = obj[list(obj.keys())[i]]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def check_quality(df: pd.DataFrame,\n",
    "                  exclude_vars: list,\n",
    "                  sum_var: str):\n",
    "\n",
    "    new_df = df.iloc[:, ~df.columns.isin(exclude_vars)]\n",
    "    checked_vars = new_df.columns[~new_df.columns.isin([sum_var])].to_list()\n",
    "\n",
    "    for idx in new_df.index:\n",
    "        row_sum = 0\n",
    "        for var in checked_vars:\n",
    "            val = new_df[var][idx]\n",
    "            if math.isnan(float(val)) != True:\n",
    "                row_sum += float(val)\n",
    "            else:\n",
    "                row_sum += 0\n",
    "        if float(new_df[sum_var][idx]) == row_sum:\n",
    "            pass\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee0f9aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/Statistical-Bulletin-on-International-Arrivals-and-Departures-2021.pdf\n",
      "The file starts from 2018.\n",
      "   Statistical-Bulletin-on-International-Arrivals-and-Departures-2021 could go wrong!\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/Migration-Report-Dec-2017.pdf\n",
      "The file starts from 2013.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/Migration-December-Report-2019.pdf\n",
      "The file starts from 2018.\n",
      "   Migration-December-Report-2019 could go wrong!\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/12-December-Migration-Report-2014.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Dec 08, 2022 3:40:26 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: inherited resources of source document are not imported to destination page\n",
      "Dec 08, 2022 3:40:26 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: call importedPage.setResources(page.getResources()) to do this\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file starts from 2010.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/12-December-Migration-Report-2015.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Dec 08, 2022 3:40:33 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: inherited resources of source document are not imported to destination page\n",
      "Dec 08, 2022 3:40:33 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: call importedPage.setResources(page.getResources()) to do this\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file starts from 2010.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/Migration-December-Report-2020.pdf\n",
      "The file starts from 2018.\n",
      "   Migration-December-Report-2020 could go wrong!\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/12-December-Migration-Report-2013.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Dec 08, 2022 3:40:43 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: inherited resources of source document are not imported to destination page\n",
      "Dec 08, 2022 3:40:43 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: call importedPage.setResources(page.getResources()) to do this\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file starts from 2010.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/tonga/12-Migration-Report-Dec-2016.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Dec 08, 2022 3:40:51 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: inherited resources of source document are not imported to destination page\n",
      "Dec 08, 2022 3:40:51 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
      "WARNING: call importedPage.setResources(page.getResources()) to do this\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file starts from 2011.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Period</th>\n",
       "      <th>Air</th>\n",
       "      <th>Ship</th>\n",
       "      <th>Yacht</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>May</td>\n",
       "      <td>3670</td>\n",
       "      <td>5303</td>\n",
       "      <td>177</td>\n",
       "      <td>9150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>January</td>\n",
       "      <td>3158</td>\n",
       "      <td>646</td>\n",
       "      <td>4</td>\n",
       "      <td>3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>February</td>\n",
       "      <td>2379</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>March</td>\n",
       "      <td>3134</td>\n",
       "      <td>853</td>\n",
       "      <td>5</td>\n",
       "      <td>3992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>April</td>\n",
       "      <td>2818</td>\n",
       "      <td>2802</td>\n",
       "      <td>30</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2021</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2021</td>\n",
       "      <td>May</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2021</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2021</td>\n",
       "      <td>Oct</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2021</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year    Period   Air  Ship Yacht Total\n",
       "0    2010       May  3670  5303   177  9150\n",
       "1    2010   January  3158   646     4  3808\n",
       "2    2010  February  2379     0     5  2384\n",
       "3    2010     March  3134   853     5  3992\n",
       "4    2010     April  2818  2802    30  5650\n",
       "..    ...       ...   ...   ...   ...   ...\n",
       "154  2021       Apr     2     0     0     2\n",
       "155  2021       May     1     8   NaN    18\n",
       "156  2021       Feb     4     1     0    41\n",
       "157  2021       Oct     8   NaN   NaN     8\n",
       "158  2021       Jan     1     8     0    18\n",
       "\n",
       "[159 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months = pd.DataFrame()\n",
    "\n",
    "for file in filepaths[:-1]:\n",
    "    print(file)\n",
    "\n",
    "    df = load_pdf(file, \"Monthly Arrival and Departure\", table_page=-5)\n",
    "    latest_year, year_idx, month_idx = split_time(df, \"Period\")\n",
    "    month = df.iloc[month_idx, 0:4]\n",
    "    start_year = detect_year(df.iloc[month_idx].iloc[0])\n",
    "\n",
    "    month = (month.dropna(how=\"all\").reset_index()\n",
    "             .drop(\"index\", axis=1))\n",
    "\n",
    "    print(f\"The file starts from {start_year}.\")\n",
    "\n",
    "    month = separate_data(month, \"Air Ship\", \" \").drop(\"Air Ship\", axis=1)\n",
    "    month = remove_separator(month)\n",
    "    month = month.replace(r'^\\s*$', 0, regex=True)\n",
    "\n",
    "    if check_quality(month, [\"Period\", \"Year\"], \"Total\") == False:\n",
    "        name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "        print(\"  \", name, \"could go wrong!\")\n",
    "\n",
    "    generate_time(month, start_year)\n",
    "    months = pd.concat([months, month], axis=0)\n",
    "    \n",
    "months = (months[[\"Year\", \"Period\", \"Air\", \"Ship\", \"Yacht\", \"Total\"]]\n",
    "          .drop_duplicates()\n",
    "          .sort_values(by=\"Year\")\n",
    "          .reset_index()\n",
    "          .drop(\"index\", axis=1))\n",
    "\n",
    "months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd174b",
   "metadata": {},
   "source": [
    "## Vanuatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449e81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = os.getcwd() + \"/data/tourism/vanuatu/2014-TM-12-December-News.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb36d759",
   "metadata": {},
   "source": [
    "### Visitor Arrivals by Purpose of Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51eaa2e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = load_pdf(pdf_path, \"Visitor Arrivals by Purpose of Visit\", 6)\n",
    "df.columns = df.iloc[0]\n",
    "\n",
    "df = df.dropna(thresh=4, axis=1).replace(\"-\", 0)\n",
    "df = df.iloc[3:].reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "splited = df[\"Conferences Stop Over\"].str.split(\" \", n=1, expand=True)\n",
    "splited.columns = [\"Conference\", \"Stopover\"]\n",
    "df = pd.concat([df, splited], axis=1)\n",
    "df = remove_separator(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2b14940",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vu_lsts = os.listdir(\"data/tourism/vanuatu\")\n",
    "dec_lst = [file for file in vu_lsts if \"Dec\" in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5757a6ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tou12_December_News_2005.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "  Tou12_December_News_2005.pdf does not find Année or Mois column.\n",
      "Tou12_December_News_2004.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "  Tou12_December_News_2004.pdf does not find Année or Mois column.\n",
      "Tou12_December_News_2007.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "  Tou12_December_News_2007.pdf does not find Année or Mois column.\n",
      "IAS_12_December_2015.pdf has started\n",
      "2012-TM-12-December_News.pdf has started\n",
      "  2012-TM-12-December_News.pdf does not find Année or Mois column.\n",
      "IAS_12_December_2016.pdf has started\n",
      "IVA_12_December_2021.pdf has started\n",
      "2014-TM-12-December-News.pdf has started\n",
      "2011-TM-12-December_News.pdf has started\n",
      "  2011-TM-12-December_News.pdf does not find Année or Mois column.\n",
      "2013-TM-12-December_News.pdf has started\n",
      "Tou12_December_2006.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "Other might have an error.\n",
      "  Tou12_December_2006.pdf does not find Année or Mois column.\n",
      "TM12_December_2009_News.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "non might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "  TM12_December_2009_News.pdf does not find Année or Mois column.\n",
      "TM12_December_2008_News.pdf has started\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "nan might have an error.\n",
      "  TM12_December_2008_News.pdf does not find Année or Mois column.\n",
      "IVA_12_December-English_2019.pdf has started\n",
      "IAS_12_December_2018.pdf has started\n",
      "IAS_12_Dececember_2017.pdf has started\n",
      "IVA_12_Dec_2020.pdf has started\n"
     ]
    }
   ],
   "source": [
    "error_dict = {\n",
    "    \"file\": [],\n",
    "    \"reason\": []\n",
    "}\n",
    "\n",
    "\n",
    "for file in dec_lst:\n",
    "    if \".pdf\" in file and \"2010\" not in file:\n",
    "\n",
    "        print(f\"{file} has started\")\n",
    "        filepath = os.getcwd() + \"/data/tourism/vanuatu/\" + file\n",
    "\n",
    "        df = load_pdf(filepath, \"Visitor Arrivals by Purpose of Visit\", 6)\n",
    "        df.columns = df.iloc[0]\n",
    "\n",
    "        df = df.dropna(thresh=4, axis=1).replace(\"-\", 0)\n",
    "        df = df.iloc[3:].reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        try:\n",
    "            col_lst = df.columns.to_list()\n",
    "            stored_splited = [\"Business, Stop\",\n",
    "                              \"Cruiseship Other\", \"Conferences Stop Over\"]\n",
    "\n",
    "            for idx, val in enumerate(col_lst):\n",
    "                if type(val) == str and val in stored_splited:\n",
    "                    if val == \"Business, Stop\":\n",
    "                        separate_data(df, \"Business, Stop\", \",\")\n",
    "\n",
    "                    elif val == \"Conferences Stop Over\":\n",
    "                        splited = df[val].str.split(\" \", n=1, expand=True)\n",
    "\n",
    "                        if len(splited.columns) == 2:\n",
    "                            splited.columns = [\n",
    "                                val.split(\" \")[0], val.split(\" \")[-1]]\n",
    "                            df = pd.concat([df, splited], axis=1)\n",
    "\n",
    "                        else:\n",
    "                            print(f\"{file} has incompatible column.\")\n",
    "                            error_dict[\"file\"].append(file)\n",
    "                            error_dict[\"reason\"].append(\"Incompatible Column\")\n",
    "\n",
    "                    else:\n",
    "                        splited = df[val].str.split(\" \", n=2, expand=True)\n",
    "\n",
    "                        if len(splited.columns) == 2:\n",
    "                            splited.columns = val.split(\" \")\n",
    "                            df = pd.concat([df, splited], axis=1)\n",
    "                        else:\n",
    "                            print(\"Incompatible Column\")\n",
    "                            error_dict[\"file\"].append(file)\n",
    "                            error_dict[\"reason\"].append(\"Incompatible Column\")\n",
    "\n",
    "            df = remove_separator(df)\n",
    "\n",
    "            try:\n",
    "                df = df.drop([\"Conferences Stop Over\",\n",
    "                             \"Année\", \"Mois\"], axis=1)\n",
    "\n",
    "                if \"Holidays\" in df.columns:\n",
    "                    df[\"Holidays\"] = df[\"Holidays\"].str.replace(\" \", \"\")\n",
    "                    saved_path = os.getcwd() + \"/data/tourism/vanuatu/temp/\" + \\\n",
    "                        file.split(\".\")[0] + \".csv\"\n",
    "                    df.to_csv(saved_path, encoding=\"utf-8\")\n",
    "\n",
    "                else:\n",
    "                    print(\"  Holidays column not found.\")\n",
    "                    error_dict[\"file\"].append(file)\n",
    "                    error_dict[\"reason\"].append(\"Holidays column not found.\")\n",
    "\n",
    "            except:\n",
    "                print(f\"  {file} does not find Année or Mois column.\")\n",
    "                error_dict[\"file\"].append(file)\n",
    "                error_dict[\"reason\"].append(\"Année or Mois column not found.\")\n",
    "\n",
    "        except:\n",
    "            error_dict[\"file\"].append(file)\n",
    "            error_dict[\"reason\"].append(\"Column Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6808469d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IVA_12_Dec_2020.csv fails to pass the quality check.\n",
      "/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/temp/IVA_12_December_2021.csv fails to pass the quality check.\n"
     ]
    }
   ],
   "source": [
    "check_lst = os.listdir(os.getcwd() + \"/data/tourism/vanuatu/temp\")\n",
    "check_lst = [os.getcwd() + \"/data/tourism/vanuatu/temp/\" + file for file in check_lst]\n",
    "\n",
    "for file in check_lst:\n",
    "    if \".DS_Store\" not in file:\n",
    "        df = pd.read_csv(file).drop(\"Unnamed: 0\", axis=1)\n",
    "        df = remove_separator(df)\n",
    "        if check_quality(df, [\"Year\", \"Month\"], \"Visitors\"):\n",
    "            df.to_csv(file, encoding=\"utf-8\")\n",
    "        else:\n",
    "            print(f\"{file} fails to pass the quality check.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c017e7e",
   "metadata": {},
   "source": [
    "### Visitor Arrivals by Usual Country of Residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a578749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tou12_December_News_2005.pdf {'table_loc': []}\n",
      "  Tou12_December_News_2005.pdf has an error.\n",
      "Tou12_December_News_2004.pdf {'table_loc': []}\n",
      "  Tou12_December_News_2004.pdf has an error.\n",
      "Tou12_December_News_2007.pdf {'table_loc': [3]}\n",
      "  Tou12_December_News_2007.pdf has an error.\n",
      "IAS_12_December_2015.pdf {'table_loc': [9]}\n",
      "  IAS_12_December_2015.pdf pass the quality check.\n",
      "2012-TM-12-December_News.pdf {'table_loc': [8]}\n",
      "  2012-TM-12-December_News.pdf could have column errors\n",
      "IAS_12_December_2016.pdf {'table_loc': [9]}\n",
      "  IAS_12_December_2016.pdf pass the quality check.\n",
      "IVA_12_December_2021.pdf {'table_loc': [6]}\n",
      "  IVA_12_December_2021.pdf has an error.\n",
      "2014-TM-12-December-News.pdf {'table_loc': [7]}\n",
      "  2014-TM-12-December-News.pdf pass the quality check.\n",
      "2011-TM-12-December_News.pdf {'table_loc': [6]}\n",
      "  2011-TM-12-December_News.pdf could have column errors\n",
      "2013-TM-12-December_News.pdf {'table_loc': [7]}\n",
      "  2013-TM-12-December_News.pdf could have column errors\n",
      "Tou12_December_2006.pdf {'table_loc': [3]}\n",
      "  Tou12_December_2006.pdf has an error.\n",
      "TM12_December_2009_News.pdf {'table_loc': [4]}\n",
      "  TM12_December_2009_News.pdf could have column errors\n",
      "TM12_December_2008_News.pdf {'table_loc': [3]}\n",
      "  TM12_December_2008_News.pdf has an error.\n",
      "IVA_12_December-English_2019.pdf {'table_loc': [10]}\n",
      "  IVA_12_December-English_2019.pdf pass the quality check.\n",
      "IAS_12_December_2018.pdf {'table_loc': [8]}\n",
      "  IAS_12_December_2018.pdf pass the quality check.\n",
      "IAS_12_Dececember_2017.pdf {'table_loc': [8]}\n",
      "  IAS_12_Dececember_2017.pdf pass the quality check.\n",
      "2010-TM-12-December_News.pdf {'table_loc': []}\n",
      "  2010-TM-12-December_News.pdf has an error.\n",
      "IVA_12_Dec_2020.pdf {'table_loc': [5]}\n",
      "  IVA_12_Dec_2020.pdf has an error.\n"
     ]
    }
   ],
   "source": [
    "bycountry_err_dict = {\n",
    "    \"file\": [],\n",
    "    \"reason\": []\n",
    "}\n",
    "\n",
    "for file in dec_lst:\n",
    "    filepath = \"/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/\" + file\n",
    "    print(file, locate_table(\n",
    "        filepath, \"Visitor Arrivals by Usual Country of Residence\", ignore_case=True))\n",
    "    try:\n",
    "        df = load_pdf(\n",
    "            filepath, \"Visitor Arrivals by Usual Country of Residence\", 2)\n",
    "        df = df.iloc[:, :-2].dropna(thresh=4, axis=1)\n",
    "\n",
    "        headers, row1 = df.columns.to_list(), df.iloc[0].to_list()\n",
    "        newheader = list()\n",
    "        for header, row in zip(headers, row1):\n",
    "            if type(header) != str:\n",
    "                newheader.append(str(row))\n",
    "            else:\n",
    "                newheader.append(str(header))\n",
    "\n",
    "        newheader[-1] = \"Total\"\n",
    "        newheader[newheader.index(\"Countries\")], newheader[newheader.index(\n",
    "            \"nan\")] = \"Other PIC\", \"Europe\"\n",
    "\n",
    "        df.columns = newheader\n",
    "        df = df.iloc[2:].reset_index().drop(\"index\", axis=1)\n",
    "        df = remove_separator(df)\n",
    "        if check_quality(df, [\"Month\", \"Year\"], \"Total\"):\n",
    "            print(f\"  {file} pass the quality check.\")\n",
    "            saved_path = \"/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/byorigin/\" + \\\n",
    "                file.split(\".\")[0] + \".csv\"\n",
    "            df.to_csv(saved_path, encoding=\"utf-8\")\n",
    "        else:\n",
    "            print(f\"  {file} could have column errors\")\n",
    "            saved_path = \"/Users/czhang/Desktop/pacific-observatory/data/tourism/vanuatu/byorigin/\" + \\\n",
    "                file.split(\".\")[0] + \".csv\"\n",
    "            df.to_csv(saved_path, encoding=\"utf-8\")\n",
    "            bycountry_err_dict[\"file\"].append(file)\n",
    "            bycountry_err_dict[\"reason\"].append(\"Column Error\")\n",
    "    except:\n",
    "        print(f\"  {file} has an error.\")\n",
    "        bycountry_err_dict[\"file\"].append(file)\n",
    "        bycountry_err_dict[\"reason\"].append(\"Missing Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71842e5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tou12_December_News_2005.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tou12_December_News_2004.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tou12_December_News_2007.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-TM-12-December_News.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IVA_12_December_2021.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-TM-12-December_News.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-TM-12-December_News.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tou12_December_2006.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TM12_December_2009_News.pdf</td>\n",
       "      <td>Column Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TM12_December_2008_News.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-TM-12-December_News.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IVA_12_Dec_2020.pdf</td>\n",
       "      <td>Missing Error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            file         reason\n",
       "0   Tou12_December_News_2005.pdf  Missing Error\n",
       "1   Tou12_December_News_2004.pdf  Missing Error\n",
       "2   Tou12_December_News_2007.pdf  Missing Error\n",
       "3   2012-TM-12-December_News.pdf   Column Error\n",
       "4       IVA_12_December_2021.pdf  Missing Error\n",
       "5   2011-TM-12-December_News.pdf   Column Error\n",
       "6   2013-TM-12-December_News.pdf   Column Error\n",
       "7        Tou12_December_2006.pdf  Missing Error\n",
       "8    TM12_December_2009_News.pdf   Column Error\n",
       "9    TM12_December_2008_News.pdf  Missing Error\n",
       "10  2010-TM-12-December_News.pdf  Missing Error\n",
       "11           IVA_12_Dec_2020.pdf  Missing Error"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bycountry_err_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13735b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Australie</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>Caledonia</th>\n",
       "      <th>Other PIC</th>\n",
       "      <th>Europe</th>\n",
       "      <th>North America</th>\n",
       "      <th>Japon</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64909</td>\n",
       "      <td>12607</td>\n",
       "      <td>9155</td>\n",
       "      <td>3708</td>\n",
       "      <td>4890</td>\n",
       "      <td>2549</td>\n",
       "      <td>642</td>\n",
       "      <td>2216</td>\n",
       "      <td>100675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58760</td>\n",
       "      <td>11927</td>\n",
       "      <td>11410</td>\n",
       "      <td>4719</td>\n",
       "      <td>4888</td>\n",
       "      <td>2395</td>\n",
       "      <td>517</td>\n",
       "      <td>2564</td>\n",
       "      <td>97180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57843</td>\n",
       "      <td>11399</td>\n",
       "      <td>11376</td>\n",
       "      <td>3397</td>\n",
       "      <td>5265</td>\n",
       "      <td>1922</td>\n",
       "      <td>630</td>\n",
       "      <td>2128</td>\n",
       "      <td>93960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65405</td>\n",
       "      <td>14430</td>\n",
       "      <td>13138</td>\n",
       "      <td>4313</td>\n",
       "      <td>5491</td>\n",
       "      <td>2094</td>\n",
       "      <td>705</td>\n",
       "      <td>2585</td>\n",
       "      <td>108161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65776</td>\n",
       "      <td>15068</td>\n",
       "      <td>12515</td>\n",
       "      <td>4874</td>\n",
       "      <td>5544</td>\n",
       "      <td>2614</td>\n",
       "      <td>659</td>\n",
       "      <td>3059</td>\n",
       "      <td>110109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>5631</td>\n",
       "      <td>688</td>\n",
       "      <td>1197</td>\n",
       "      <td>374</td>\n",
       "      <td>365</td>\n",
       "      <td>189</td>\n",
       "      <td>49</td>\n",
       "      <td>201</td>\n",
       "      <td>8693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>5995</td>\n",
       "      <td>746</td>\n",
       "      <td>1410</td>\n",
       "      <td>696</td>\n",
       "      <td>373</td>\n",
       "      <td>158</td>\n",
       "      <td>51</td>\n",
       "      <td>204</td>\n",
       "      <td>9633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>5785</td>\n",
       "      <td>759</td>\n",
       "      <td>1460</td>\n",
       "      <td>333</td>\n",
       "      <td>340</td>\n",
       "      <td>109</td>\n",
       "      <td>52</td>\n",
       "      <td>152</td>\n",
       "      <td>8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>5653</td>\n",
       "      <td>757</td>\n",
       "      <td>1458</td>\n",
       "      <td>247</td>\n",
       "      <td>341</td>\n",
       "      <td>105</td>\n",
       "      <td>49</td>\n",
       "      <td>145</td>\n",
       "      <td>8755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2387</td>\n",
       "      <td>354</td>\n",
       "      <td>814</td>\n",
       "      <td>403</td>\n",
       "      <td>367</td>\n",
       "      <td>130</td>\n",
       "      <td>59</td>\n",
       "      <td>186</td>\n",
       "      <td>4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mar</td>\n",
       "      <td>3970</td>\n",
       "      <td>641</td>\n",
       "      <td>707</td>\n",
       "      <td>277</td>\n",
       "      <td>332</td>\n",
       "      <td>131</td>\n",
       "      <td>52</td>\n",
       "      <td>233</td>\n",
       "      <td>6343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr</td>\n",
       "      <td>5021</td>\n",
       "      <td>838</td>\n",
       "      <td>991</td>\n",
       "      <td>270</td>\n",
       "      <td>335</td>\n",
       "      <td>133</td>\n",
       "      <td>58</td>\n",
       "      <td>214</td>\n",
       "      <td>7860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>May</td>\n",
       "      <td>4091</td>\n",
       "      <td>821</td>\n",
       "      <td>1198</td>\n",
       "      <td>454</td>\n",
       "      <td>410</td>\n",
       "      <td>219</td>\n",
       "      <td>59</td>\n",
       "      <td>222</td>\n",
       "      <td>7474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jun</td>\n",
       "      <td>6248</td>\n",
       "      <td>1690</td>\n",
       "      <td>726</td>\n",
       "      <td>310</td>\n",
       "      <td>523</td>\n",
       "      <td>203</td>\n",
       "      <td>52</td>\n",
       "      <td>224</td>\n",
       "      <td>9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul</td>\n",
       "      <td>6937</td>\n",
       "      <td>2032</td>\n",
       "      <td>1188</td>\n",
       "      <td>433</td>\n",
       "      <td>633</td>\n",
       "      <td>216</td>\n",
       "      <td>95</td>\n",
       "      <td>236</td>\n",
       "      <td>11770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aug</td>\n",
       "      <td>6043</td>\n",
       "      <td>2049</td>\n",
       "      <td>928</td>\n",
       "      <td>298</td>\n",
       "      <td>646</td>\n",
       "      <td>181</td>\n",
       "      <td>58</td>\n",
       "      <td>202</td>\n",
       "      <td>10405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sep</td>\n",
       "      <td>7640</td>\n",
       "      <td>1827</td>\n",
       "      <td>1227</td>\n",
       "      <td>451</td>\n",
       "      <td>462</td>\n",
       "      <td>231</td>\n",
       "      <td>59</td>\n",
       "      <td>285</td>\n",
       "      <td>12182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct</td>\n",
       "      <td>5960</td>\n",
       "      <td>1505</td>\n",
       "      <td>1072</td>\n",
       "      <td>334</td>\n",
       "      <td>576</td>\n",
       "      <td>216</td>\n",
       "      <td>41</td>\n",
       "      <td>218</td>\n",
       "      <td>9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nov</td>\n",
       "      <td>4622</td>\n",
       "      <td>790</td>\n",
       "      <td>1071</td>\n",
       "      <td>293</td>\n",
       "      <td>505</td>\n",
       "      <td>156</td>\n",
       "      <td>55</td>\n",
       "      <td>212</td>\n",
       "      <td>7704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec</td>\n",
       "      <td>6833</td>\n",
       "      <td>1126</td>\n",
       "      <td>1758</td>\n",
       "      <td>543</td>\n",
       "      <td>361</td>\n",
       "      <td>173</td>\n",
       "      <td>68</td>\n",
       "      <td>208</td>\n",
       "      <td>11070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>4591</td>\n",
       "      <td>621</td>\n",
       "      <td>1428</td>\n",
       "      <td>231</td>\n",
       "      <td>364</td>\n",
       "      <td>135</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>7612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2448</td>\n",
       "      <td>429</td>\n",
       "      <td>876</td>\n",
       "      <td>440</td>\n",
       "      <td>340</td>\n",
       "      <td>154</td>\n",
       "      <td>26</td>\n",
       "      <td>218</td>\n",
       "      <td>4931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mar</td>\n",
       "      <td>4405</td>\n",
       "      <td>718</td>\n",
       "      <td>720</td>\n",
       "      <td>344</td>\n",
       "      <td>388</td>\n",
       "      <td>135</td>\n",
       "      <td>36</td>\n",
       "      <td>231</td>\n",
       "      <td>6977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr</td>\n",
       "      <td>4931</td>\n",
       "      <td>994</td>\n",
       "      <td>1126</td>\n",
       "      <td>522</td>\n",
       "      <td>533</td>\n",
       "      <td>222</td>\n",
       "      <td>58</td>\n",
       "      <td>276</td>\n",
       "      <td>8662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>May</td>\n",
       "      <td>4669</td>\n",
       "      <td>959</td>\n",
       "      <td>971</td>\n",
       "      <td>293</td>\n",
       "      <td>374</td>\n",
       "      <td>165</td>\n",
       "      <td>62</td>\n",
       "      <td>177</td>\n",
       "      <td>7670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>June</td>\n",
       "      <td>6911</td>\n",
       "      <td>1901</td>\n",
       "      <td>971</td>\n",
       "      <td>461</td>\n",
       "      <td>419</td>\n",
       "      <td>279</td>\n",
       "      <td>39</td>\n",
       "      <td>225</td>\n",
       "      <td>11206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July</td>\n",
       "      <td>7091</td>\n",
       "      <td>2319</td>\n",
       "      <td>805</td>\n",
       "      <td>384</td>\n",
       "      <td>654</td>\n",
       "      <td>217</td>\n",
       "      <td>47</td>\n",
       "      <td>338</td>\n",
       "      <td>11855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aug</td>\n",
       "      <td>5781</td>\n",
       "      <td>2121</td>\n",
       "      <td>1167</td>\n",
       "      <td>444</td>\n",
       "      <td>672</td>\n",
       "      <td>245</td>\n",
       "      <td>88</td>\n",
       "      <td>279</td>\n",
       "      <td>10797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sep</td>\n",
       "      <td>7660</td>\n",
       "      <td>1664</td>\n",
       "      <td>790</td>\n",
       "      <td>458</td>\n",
       "      <td>399</td>\n",
       "      <td>269</td>\n",
       "      <td>67</td>\n",
       "      <td>289</td>\n",
       "      <td>11596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct</td>\n",
       "      <td>6431</td>\n",
       "      <td>1614</td>\n",
       "      <td>1196</td>\n",
       "      <td>418</td>\n",
       "      <td>523</td>\n",
       "      <td>311</td>\n",
       "      <td>65</td>\n",
       "      <td>269</td>\n",
       "      <td>10827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nov</td>\n",
       "      <td>4735</td>\n",
       "      <td>830</td>\n",
       "      <td>1107</td>\n",
       "      <td>413</td>\n",
       "      <td>448</td>\n",
       "      <td>239</td>\n",
       "      <td>86</td>\n",
       "      <td>265</td>\n",
       "      <td>8123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec</td>\n",
       "      <td>6123</td>\n",
       "      <td>898</td>\n",
       "      <td>1358</td>\n",
       "      <td>466</td>\n",
       "      <td>430</td>\n",
       "      <td>243</td>\n",
       "      <td>53</td>\n",
       "      <td>282</td>\n",
       "      <td>9853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    Year Month  Australie  New Zealand  Caledonia  Other PIC  \\\n",
       "0            0  2009.0   NaN      64909        12607       9155       3708   \n",
       "1            1  2010.0   NaN      58760        11927      11410       4719   \n",
       "2            2  2011.0   NaN      57843        11399      11376       3397   \n",
       "3            3  2012.0   NaN      65405        14430      13138       4313   \n",
       "4            4  2013.0   NaN      65776        15068      12515       4874   \n",
       "5            5  2009.0   Dec       5631          688       1197        374   \n",
       "6            6  2010.0   Dec       5995          746       1410        696   \n",
       "7            7  2011.0   Dec       5785          759       1460        333   \n",
       "8            8  2012.0   Jan       5653          757       1458        247   \n",
       "9            9     NaN   Feb       2387          354        814        403   \n",
       "10          10     NaN   Mar       3970          641        707        277   \n",
       "11          11     NaN   Apr       5021          838        991        270   \n",
       "12          12     NaN   May       4091          821       1198        454   \n",
       "13          13     NaN   Jun       6248         1690        726        310   \n",
       "14          14     NaN   Jul       6937         2032       1188        433   \n",
       "15          15     NaN   Aug       6043         2049        928        298   \n",
       "16          16     NaN   Sep       7640         1827       1227        451   \n",
       "17          17     NaN   Oct       5960         1505       1072        334   \n",
       "18          18     NaN   Nov       4622          790       1071        293   \n",
       "19          19     NaN   Dec       6833         1126       1758        543   \n",
       "20          20  2013.0   Jan       4591          621       1428        231   \n",
       "21          21     NaN   Feb       2448          429        876        440   \n",
       "22          22     NaN   Mar       4405          718        720        344   \n",
       "23          23     NaN   Apr       4931          994       1126        522   \n",
       "24          24     NaN   May       4669          959        971        293   \n",
       "25          25     NaN  June       6911         1901        971        461   \n",
       "26          26     NaN  July       7091         2319        805        384   \n",
       "27          27     NaN   Aug       5781         2121       1167        444   \n",
       "28          28     NaN   Sep       7660         1664        790        458   \n",
       "29          29     NaN   Oct       6431         1614       1196        418   \n",
       "30          30     NaN   Nov       4735          830       1107        413   \n",
       "31          31     NaN   Dec       6123          898       1358        466   \n",
       "\n",
       "    Europe  North America  Japon  Countries   Total  \n",
       "0     4890           2549    642       2216  100675  \n",
       "1     4888           2395    517       2564   97180  \n",
       "2     5265           1922    630       2128   93960  \n",
       "3     5491           2094    705       2585  108161  \n",
       "4     5544           2614    659       3059  110109  \n",
       "5      365            189     49        201    8693  \n",
       "6      373            158     51        204    9633  \n",
       "7      340            109     52        152    8990  \n",
       "8      341            105     49        145    8755  \n",
       "9      367            130     59        186    4700  \n",
       "10     332            131     52        233    6343  \n",
       "11     335            133     58        214    7860  \n",
       "12     410            219     59        222    7474  \n",
       "13     523            203     52        224    9976  \n",
       "14     633            216     95        236   11770  \n",
       "15     646            181     58        202   10405  \n",
       "16     462            231     59        285   12182  \n",
       "17     576            216     41        218    9922  \n",
       "18     505            156     55        212    7704  \n",
       "19     361            173     68        208   11070  \n",
       "20     364            135     32        210    7612  \n",
       "21     340            154     26        218    4931  \n",
       "22     388            135     36        231    6977  \n",
       "23     533            222     58        276    8662  \n",
       "24     374            165     62        177    7670  \n",
       "25     419            279     39        225   11206  \n",
       "26     654            217     47        338   11855  \n",
       "27     672            245     88        279   10797  \n",
       "28     399            269     67        289   11596  \n",
       "29     523            311     65        269   10827  \n",
       "30     448            239     86        265    8123  \n",
       "31     430            243     53        282    9853  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_lst = os.listdir(\"data/tourism/vanuatu/byorigin/\")\n",
    "temp_lst = [os.getcwd() + \"/data/tourism/vanuatu/byorigin/\" +\n",
    "            file for file in temp_lst]\n",
    "\n",
    "test = pd.read_csv(temp_lst[4])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a3441",
   "metadata": {},
   "source": [
    "## PDFMINER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d967914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "\n",
    "output_string = StringIO()\n",
    "with open(pdf_path, 'rb') as in_file:\n",
    "    parser = PDFParser(in_file)\n",
    "    doc = PDFDocument(parser)\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    for page in PDFPage.create_pages(doc):\n",
    "        interpreter.process_page(page)\n",
    "        \n",
    "output_string.getvalue()"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Desktop/PO-Tourism/parse_demo.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "345.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
