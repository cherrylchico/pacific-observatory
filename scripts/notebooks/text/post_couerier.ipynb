{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "303883ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import urllib.request\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac80636",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_path = os.getcwd() + \"/data/text/png\"\n",
    "if not os.path.exists(checked_path):\n",
    "    os.makedirs(checked_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e99f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(url, timeout):\n",
    "    with urllib.request.urlopen(url, timeout=timeout) as conn:\n",
    "        content = conn.read()\n",
    "        return content\n",
    "def extract_info(url, timeout):\n",
    "    content = load_page(url, timeout)\n",
    "    soup = BeautifulSoup(content)\n",
    "    info_dict = {\"url\": [], \"title\": [], \"date\": []}\n",
    "    for a in soup.find_all(class_=\"entry-container\"):\n",
    "        entry_title = a.find(class_=\"entry-title\")\n",
    "        info_dict[\"date\"].append(a.find(class_=\"entry-date\").text)\n",
    "        if entry_title is not None:\n",
    "            info_dict[\"url\"].append(entry_title.find(\"a\").attrs[\"href\"])\n",
    "            info_dict[\"title\"].append(entry_title.text)\n",
    "        else:\n",
    "            info_dict[\"url\"].append(a.find(\"a\").attrs[\"href\"])\n",
    "            info_dict[\"title\"].append(\"Missing Title.\")\n",
    "        pbar.update(1)\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d865afd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████▉| 15481/15490 [02:58<00:00, 86.73it/s]\n"
     ]
    }
   ],
   "source": [
    "host = \"https://www.postcourier.com.pg/national-news/page/\"\n",
    "urls = [host + str(i) for i in range(1, 1550)]\n",
    "output = []\n",
    "with tqdm(total=len(urls)*10) as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:  \n",
    "        future_to_url = {executor.submit(extract_info, url, 10): url for url in urls}\n",
    "        for future in as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (url, exc))\n",
    "            else:\n",
    "                output.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383cca9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.postcourier.com.pg/law-students-go...</td>\n",
       "      <td>Law students go to court training</td>\n",
       "      <td>July 13, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.postcourier.com.pg/mou-signed-to-p...</td>\n",
       "      <td>MOU signed to promote quality nurse training i...</td>\n",
       "      <td>July 13, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.postcourier.com.pg/pm-backs-icac-s...</td>\n",
       "      <td>PM backs ICAC set up</td>\n",
       "      <td>July 13, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.postcourier.com.pg/22kg-marijuana-...</td>\n",
       "      <td>22kg marijuana bust</td>\n",
       "      <td>July 13, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.postcourier.com.pg/fresh-vegetable...</td>\n",
       "      <td>Fresh vegetables galore at Mt Hagen market</td>\n",
       "      <td>July 13, 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.postcourier.com.pg/law-students-go...   \n",
       "1  https://www.postcourier.com.pg/mou-signed-to-p...   \n",
       "2  https://www.postcourier.com.pg/pm-backs-icac-s...   \n",
       "3  https://www.postcourier.com.pg/22kg-marijuana-...   \n",
       "4  https://www.postcourier.com.pg/fresh-vegetable...   \n",
       "\n",
       "                                               title           date  \n",
       "0                  Law students go to court training  July 13, 2023  \n",
       "1  MOU signed to promote quality nurse training i...  July 13, 2023  \n",
       "2                               PM backs ICAC set up  July 13, 2023  \n",
       "3                                22kg marijuana bust  July 13, 2023  \n",
       "4         Fresh vegetables galore at Mt Hagen market  July 13, 2023  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_urls = pd.DataFrame()\n",
    "for out in output:\n",
    "    df = pd.DataFrame(out)\n",
    "    if news_urls.empty:\n",
    "        news_urls = df\n",
    "    else:\n",
    "        news_urls = (pd.concat([news_urls, df], axis=0)\n",
    "                     .drop_duplicates()\n",
    "                     .reset_index()\n",
    "                     .drop(\"index\", axis=1))\n",
    "\n",
    "news_urls.to_csv(checked_path + \"/post_courier_urls.csv\", encoding=\"utf-8\")\n",
    "news_urls.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95977130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_news(url, timeout):\n",
    "    content = load_page(url, timeout)\n",
    "    soup = BeautifulSoup(content)\n",
    "    raw_text = soup.find(class_ = \"entry-content\").text  \n",
    "    tag = soup.find(class_ = \"tags-links\")\n",
    "    if tag is not None:\n",
    "        tag_text = tag.text\n",
    "    else:\n",
    "        tag_text = \"No Tag\"\n",
    "    pbar.update(1)\n",
    "    return url, raw_text, tag_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ecbecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27999it [30:44, 14.25it/s]                                                                                            "
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "news_lst = []\n",
    "with tqdm(total=len(news_urls)) as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=num_cpus-1) as executor:  \n",
    "        futures = {executor.submit(extract_news, url, 10): url for url in news_urls.url}\n",
    "        for future in as_completed(futures):\n",
    "            url = futures[future]\n",
    "            try:\n",
    "                url, news, tag = future.result()\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (url, exc))\n",
    "            else:\n",
    "                news_lst.append((url, news, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cb18ac1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame(news_lst, columns=[\"url\", \"news\", \"tag\"])\n",
    "news_df.to_csv(checked_path + \"/post_courier_news.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
